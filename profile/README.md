# ğŸ›ï¸ Windy Civi Pipelines

**Production-scale data infrastructure for U.S. legislative transparency**

This GitHub organization maintains the backend data pipelines that power [Windy Civi](https://github.com/windy-civi) â€” an open-source initiative to make legislative data permanent, verifiable, and accessible.

We build **reliable, reproducible pipelines** that process legislative data from all 50 states and Congress, creating a blockchain-style archive that survives administration changes, website redesigns, and data loss.

[![Main Repository](https://img.shields.io/badge/Main_Repo-opencivicdata--blockchain--transformer-blue)](https://github.com/windy-civi/opencivicdata-blockchain-transformer)
[![Active Pipelines](https://img.shields.io/badge/Active_Pipelines-14-green)](https://github.com/windy-civi-pipelines)

---

## ğŸ¯ What We Do

Each state repository in this organization runs automated workflows that:

- ğŸ” **Scrape** legislative data nightly using [OpenStates](https://github.com/openstates/openstates-scrapers) scrapers
- ğŸ§¼ **Sanitize** output by removing ephemeral fields for deterministic versioning
- ğŸ§  **Structure** data in blockchain-style directories with full provenance tracking
- ğŸ”— **Link** bills, votes, and events across sessions and chambers
- ğŸ“„ **Extract** full text from PDFs, XMLs, and HTML (multi-format fallback)
- ğŸ“Š **Monitor** data quality with automated orphan detection
- ğŸ“‚ **Commit** processed data to GitHub for permanent, auditable storage

**Result:** A complete, versioned legislative record for each state â€” resilient to source changes and always accessible.

---

## ğŸ—ï¸ Architecture Highlights

### Production Features

âœ… **Incremental Processing** - Only processes new/changed bills (no wasted compute)  
âœ… **Auto-Save Failsafe** - Commits every 30 minutes to survive 6-hour GitHub Actions timeout  
âœ… **Data Quality Monitoring** - Tracks orphaned bills (votes without bill data) to catch scraper issues  
âœ… **Concurrent Updates** - Multiple jobs can safely update repos with git rebase conflict resolution  
âœ… **Multi-Format Text Extraction** - XML â†’ HTML â†’ PDF fallback with strikethrough detection  
âœ… **Fault Tolerance** - Individual bill failures don't block the entire pipeline  

### Technical Stack

- **Orchestration:** GitHub Actions (Docker + Python)
- **Language:** Python 3.12+ (pipenv, black, type hints)
- **Text Extraction:** pdfplumber, PyPDF2, BeautifulSoup4, lxml
- **Data Format:** JSON with ISO timestamps and semantic versioning
- **Storage:** Git (GitHub) for versioning + permanent URLs

---

## ğŸ“Š Current Status

| Jurisdiction          | Status        | Bills Tracked | Last Updated |
| --------------------- | ------------- | ------------- | ------------ |
| ğŸ‡ºğŸ‡¸ **Federal (USA)**  | âœ… Production | ~15,000+      | Daily        |
| ğŸ›ï¸ **Illinois (IL)**  | âœ… Production | ~8,000+       | Daily        |
| ğŸ›ï¸ **Tennessee (TN)** | âœ… Production | ~2,000+       | Daily        |
| ğŸ›ï¸ **Texas (TX)**     | âœ… Production | ~7,000+       | Daily        |
| ğŸ›ï¸ **Wisconsin (WI)** | âœ… Production | ~1,500+       | Daily        |
| ğŸ›ï¸ **Wyoming (WY)**   | âœ… Production | ~500+         | Daily        |
| ...                   | ğŸš§ Onboarding | -             | -            |

**Template Repository:** [windy-civi-template-pipeline](https://github.com/windy-civi-pipelines/windy-civi-template-pipeline)

---

## ğŸ—‚ï¸ Data Format

Each state repository produces structured, version-controlled output:

```
data_output/
â”œâ”€â”€ data_processed/
â”‚   â””â”€â”€ country:us/state:il/
â”‚       â””â”€â”€ sessions/103/
â”‚           â”œâ”€â”€ bills/
â”‚           â”‚   â””â”€â”€ HB1234/
â”‚           â”‚       â”œâ”€â”€ metadata.json           # Bill data + processing timestamps
â”‚           â”‚       â”œâ”€â”€ files/                  # Extracted text
â”‚           â”‚       â”‚   â”œâ”€â”€ HB1234_text.xml
â”‚           â”‚       â”‚   â”œâ”€â”€ HB1234_text.pdf
â”‚           â”‚       â”‚   â””â”€â”€ HB1234_text_extracted.txt
â”‚           â”‚       â””â”€â”€ logs/                   # Actions, votes, events
â”‚           â””â”€â”€ events/                         # Committee hearings
â”œâ”€â”€ orphaned_placeholders_tracking.json  # Data quality monitoring
â””â”€â”€ data_not_processed/                  # Error logs by category
```

**Key Features:**

- `_processing` timestamps track when logs and text were last updated
- Incremental updates only touch changed bills
- Orphan tracking identifies bills with votes/events but no metadata
- Errors categorized by type (download failures, parsing errors, etc.)

---

## ğŸ”§ Pipeline Architecture

Pipelines run as **modular GitHub Actions** in two stages:

### Stage 1: Scrape & Format (Sequential Jobs)

1. **Scrape** - Docker-based OpenStates scraper
2. **Format** - Process data, link events, monitor quality

### Stage 2: Text Extraction (Independent)

- Runs separately to handle 4-6 hour extraction times
- Auto-saves progress every 30 minutes
- Resumes on restart if timeout occurs

**Why this design?**

- Decouples fast metadata updates from slow text extraction
- Prevents scraping from blocking on extraction timeouts
- Enables independent debugging of each stage
- Allows selective re-runs (e.g., re-extract without re-scraping)

---

## ğŸ› ï¸ Technologies & Patterns

**Patterns Implemented:**

- Incremental processing with timestamp-based change detection
- Two-level timestamps (bill-level + action-level)
- Fault-tolerant design (individual failures don't block pipeline)
- Data quality monitoring with orphan detection
- Auto-save for long-running processes
- Git-based conflict resolution for concurrent updates

**Code Quality:**

- Type hints throughout
- Black code formatting
- Modular handler/utility architecture
- Comprehensive error logging
- Unit + integration tests

---

## ğŸ§ª Testing & Validation

Each pipeline includes:

- âœ… Test suite with synthetic and real data
- âœ… Incremental processing validation (100% skip rate on re-runs)
- âœ… Orphan detection with multi-run simulation
- âœ… Text extraction with multi-format fallback testing

**Example:** USA pipeline test with 205 bills - all placeholders cleaned, 0 orphans detected.

---

## ğŸ“š Documentation

Comprehensive docs in the main repository:

- **[Main Repository](https://github.com/windy-civi/opencivicdata-blockchain-transformer)** - Full technical documentation
- **[Setup Guide](https://github.com/windy-civi/opencivicdata-blockchain-transformer/blob/main/docs/for-caller-repos/README_TEMPLATE.md)** - State pipeline setup
- **[Incremental Processing](https://github.com/windy-civi/opencivicdata-blockchain-transformer/blob/main/docs/incremental_processing/)** - How updates work
- **[Orphan Tracking](https://github.com/windy-civi/opencivicdata-blockchain-transformer/blob/main/docs/orphan_tracking.md)** - Data quality monitoring

---

## ğŸš€ Current Development: Civic Engagement Bots

We're building **automated social media bots** that turn legislative data into actionable content for organizations, advocacy groups, and elected officials.

**Why bots?** We built a civic engagement app first - and nobody used it. The lesson: don't make people come to _your_ platform. **Meet people where they already are** (Twitter, BlueSky, etc.). Instead of building another civic tech app that sits unused, we're integrating legislative transparency into the feeds people already follow.

### How It Works

Organizations sign up and configure:

- **Topics of interest** (keywords, policy areas, bill sponsors)
- **Social platforms** (BlueSky, Twitter/X, etc.)
- **Posting preferences** (frequency, format, tone)

The system automatically:

1. Monitors legislative activity across all states
2. Matches new bills/actions to org-specific topics
3. Generates shareable posts (summaries, links, impact notes)
4. Publishes to configured social accounts

### Example Use Cases

**Advocacy Organizations:**

- **Black Lives Matter** â†’ Auto-post bills about criminal justice reform, police accountability, voting rights
- **LGBTQIA+ Groups** â†’ Track legislation affecting LGBTQ+ rights, healthcare access, discrimination laws
- **Environmental Orgs** â†’ Monitor climate policy, renewable energy bills, conservation funding

**Elected Officials:**

- **State Senators** â†’ Auto-post when they sponsor or co-sponsor legislation
- **U.S. Congress** â†’ Share bills they vote on with constituent-friendly summaries
- **Local Representatives** â†’ Keep constituents informed about state-level impacts

**Researchers & Journalists:**

- **Policy Think Tanks** â†’ Track legislation in specific domains (education, healthcare, housing)
- **News Outlets** â†’ Get alerts on high-impact bills before they become news

### Technical Architecture

- **Data Pipeline** â†’ Provides clean, structured, timestamped bill data
- **AI Layer** â†’ Summarizes bills, extracts themes, identifies relevance
- **Bot Engine** â†’ Generates platform-specific posts, manages posting schedules
- **API** â†’ Allows orgs to configure topics, approve/reject posts, view analytics

**Why this matters:** Most people don't read legislative data, but they _do_ follow organizations they trust on social media. This bridges that gap â€” making legislative transparency automatic, accessible, and actionable.

---

## ğŸ—ºï¸ Roadmap

**Phase 1: Infrastructure** âœ…

- âœ… Incremental processing (complete)
- âœ… Auto-save failsafe (complete)
- âœ… Orphan tracking (complete)
- ğŸš§ Expanding to all 50 states
- ğŸš§ Historical data backfill

**Phase 2: Intelligence Layer** ğŸš§

- ğŸš§ AI-powered bill summarization
- ğŸš§ Topic classification and keyword matching
- ğŸš§ Impact analysis (who's affected, how)
- ğŸš§ Automated post generation

**Phase 3: Engagement Platform** ğŸ“‹

- ğŸ“‹ Organization signup and configuration
- ğŸ“‹ Social media API integrations
- ğŸ“‹ Post approval workflows
- ğŸ“‹ Analytics dashboard

**Phase 4: Decentralization** ğŸ”®

- Integration with decentralized storage (IPFS)
- Blockchain-based provenance tracking
- Federated bot hosting

---

## ğŸ¤– Development Notes

This project was built with AI assistance (ChatGPT, Cursor) as technical collaborators. AI helped with:

- Architecture exploration and design tradeoffs
- Workflow refactoring and optimization
- Documentation and error handling
- Debugging complex edge cases

The result: more maintainable code, better documentation, and faster iteration â€” while deepening my understanding of distributed systems, data pipelines, and production-grade automation.

---

## ğŸ¤ Contributing

Interested in civic tech? We welcome:

- ğŸ›ï¸ **State pipeline onboarding** - Help add your state
- ğŸ› **Bug reports** - Found an issue? Open a ticket
- ğŸ’¡ **Feature ideas** - Suggest improvements
- ğŸ“– **Documentation** - Help clarify setup or usage

**Getting Started:**

1. Check out the [main repository](https://github.com/windy-civi/opencivicdata-blockchain-transformer)
2. Review the [setup guide](https://github.com/windy-civi/opencivicdata-blockchain-transformer/blob/main/docs/for-caller-repos/README_TEMPLATE.md)
3. Open an issue or PR

---

## ğŸ“« Contact

- **Main Project:** [Windy Civi](https://github.com/windy-civi)
- **Website:** [windycivi.com](https://windycivi.com)
- **Organization:** Chicago-based civic tech initiative

---

**Building open, durable civic infrastructure â€” one state at a time.** ğŸ›ï¸

_Part of the [Windy Civi](https://github.com/windy-civi) ecosystem._
